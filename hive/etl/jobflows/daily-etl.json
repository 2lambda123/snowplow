[
  {
    "Name": "ETL Step 1: Create the SnowPlow event table",
    "ActionOnFailure": "TERMINATE_JOB_FLOW",
    "HadoopJarStep": {
      "Jar": "/home/hadoop/contrib/streaming/hadoop-0.18-streaming.jar",
      "Args": [
         "-input",     "s3n://elasticmapreduce/samples/freebase/input/",
         "-output",    "s3n://<bucket>/freebase/step1out/",
         "-mapper",    "s3n://elasticmapreduce/samples/freebase/code/mapper.py"
      ]
    }
  },
  {
    "Name": "ETL Step 2: extract CloudFront log files to a temporary SnowPlow data table",
    "ActionOnFailure": "TERMINATE_JOB_FLOW",
    "HadoopJarStep": {
      "Jar": "/home/hadoop/contrib/streaming/hadoop-0.18-streaming.jar",
      "Args": [
         "-input",     "s3n://<bucket>/freebase/step1out/",
         "-output",    "s3n://<bucket>/freebase/step2out/",
         "-mapper",    "s3n://elasticmapreduce/samples/freebase/code/top_sdb_mapper.rb",
         "-reducer",   "s3n://elasticmapreduce/samples/freebase/code/top_sdb_reducer.rb",
         "-cacheFile", "s3n://elasticmapreduce/samples/freebase/code/base64.rb#base64.rb",
         "-cacheFile", "s3n://elasticmapreduce/samples/freebase/code/aws_sdb.rb#aws_sdb.rb"
      ]
    }
  },
  {
    "Name": "ETL Step 3: Load the temporary event data into the SnowPlow event table",
    "ActionOnFailure": "TERMINATE_JOB_FLOW",
    "HadoopJarStep": {
      "Jar": "/home/hadoop/contrib/streaming/hadoop-0.18-streaming.jar",
      "Args": [
         "-input",     "s3n://elasticmapreduce/samples/freebase/input/",
         "-output",    "s3n://<bucket>/freebase/names/step1",
         "-mapper",    "s3n://elasticmapreduce/samples/freebase/code/name_mapper.rb",
         "-reducer",   "s3n://elasticmapreduce/samples/freebase/code/name_reducer.rb",
         "-cacheFile", "s3n://elasticmapreduce/samples/freebase/code/base64.rb#base64.rb",
         "-cacheFile", "s3n://elasticmapreduce/samples/freebase/code/aws_sdb.rb#aws_sdb.rb"
      ]
    }
  }
]
